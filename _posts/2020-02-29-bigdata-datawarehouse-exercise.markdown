---
layout: post
title:  "大数据数据仓库实验目录"
date:   2020-02-29 11:54:38 +0800
categories: bigdata experiment enviroment
---


###  第1章 基础
#### 1.1实验目标
#### 1.2环境准备	
 * [1.2.1虚拟机准备]({% post_url 2020-02-29-bigdata-experiment-environment %})
 * [1.2.2 SSH免密登录]({% post_url 2020-02-29-bigdata-experiment-environment %})
 * [1.2.3 集群同步脚本]({% post_url 2020-03-06-xsync-shell-script %})
 * [1.2.4 安装JDK]({% post_url 2020-03-05-jdk-centos-install %})
 * [1.2.5 集群整体操作脚本]({% post_url 2020-03-06-xcall-shell-script %})
 * [1.2.6 安装MySQL]({% post_url 2020-03-05-mysql-centos-install %})
 * [1.2.7 创建CM用的数据库]({% post_url 2020-02-29-bigdata-experiment-environment %})
 * [1.2.8 下载第三方依赖]({% post_url 2020-02-29-bigdata-experiment-environment %})
 * [1.2.9 关闭SELINUX]({% post_url 2020-03-06-centos-selinux %})

#### 1.3 CM安装部署	7
 * 1.3.1 CM下载地址	7
 * 1.3.2 CM安装	7
 * 1.3.3 启动CM服务	9
 * 1.3.4 关闭CM服务	10

#### 1.4 CM的集群部署	10
 * 1.4.1 接受条款和协议	10
 * 1.4.2 选择免费	11
 * 1.4.3 指定主机	11
 * 1.4.4 选择CDH的版本5.12.1	12
 * 1.4.5 等待下载安装	12

### 第2章 数据采集模块	13
#### 2.1 HDFS、YARN、Zookeeper安装	13
 * 2.1.1 选择自定义安装	13
 * 2.1.2 选择安装服务	14
 * 2.1.3 分配节点	15
 * 2.1.4 集群设置全部选默认即可	15
 * 2.1.5 自动启动进程	16
 * 2.1.6 修改HDFS的权限检查配置	16
 * 2.1.7 配置Hadoop支持LZO	16

#### 2.2 Flume安装	18
 * 2.2.1 日志采集Flume安装	18
 * 2.2.2 日志采集Flume配置	20
 * 2.2.3 Flume拦截器	23

#### 2.3 Kafka安装	29
 * 2.3.1 导入离线包	30
 * 2.3.2 在线下载安装包（不选）	30
 * 2.3.3 Kafka安装	31
 * 2.3.4 查看Kafka Topic	35
 * 2.2.5 创建 Kafka Topic	35
 * 2.3.6 删除 Kafka Topic	35
 * 2.3.7 生产消息	36
 * 2.3.8 消费消息	36
 * 2.3.9 查看某个Topic的详情	36

#### 2.4 Flume消费Kafka数据写到HDFS	36
#### 2.5 日志生成数据传输到HDFS	38
### 第3章 数仓搭建环境准备	39
#### 3.1 Hive安装	39
#### 3.2 Oozie安装	43
 * 3.2.1 添加Oozie服务	43
 * 3.2.2 选择集群节点	44
 * 3.2.3 选择有MySQL的节点安装	44
 * 3.2.4 链接数据库	45
 * 3.2.5 一路继续到完成	45

#### 3.3 Hue安装	45
 * 3.3.1 Hue概述	45
 * 3.3.2 安装前的准备	46
 * 3.3.3 HUE安装步骤	46

### 第4章 用户行为数仓搭建	49
#### 4.1 ODS层	49
 * 4.1.1 创建数据库	49
 * 4.1.2 创建启动日志表ods_start_log	49
 * 4.1.3 ODS层加载数据脚本	49

#### 4.2 DWD层启动表数据解析	50
 * 4.2.1 创建启动表	50
 * 4.2.2 DWD层启动表加载数据脚本	51

#### 4.3 DWS层（需求：用户日活跃）	52
 * 4.3.1 每日活跃设备明细	52
 * 4.3.2 DWS层加载数据脚本	53

#### 4.4 ADS层（需求：用户日活跃）	54
 * 4.4.1 活跃设备数	54
 * 4.4.2 ADS层加载数据脚本	54

### 第5章 业务数仓搭建	55
#### 5.1 业务数据生成	55
 * 5.1.1 建表语句	55
 * 5.1.2 生成业务数据	56

#### 5.2 业务数据导入数仓	57
 * 5.2.1 Sqoop安装	58
 * 5.2.2 Sqoop定时导入脚本	59

#### 5.3 ODS层	61
 * 5.3.1 创建订单表	61
 * 5.3.2 创建订单详情表	62
 * 5.3.3 创建商品表	62
 * 5.3.4 创建用户表	63
 * 5.3.5 创建商品一级分类表	63
 * 5.3.6 创建商品二级分类表	63
 * 5.3.7 创建商品三级分类表	63
 * 5.3.8 创建支付流水表	64
 * 5.3.9 ODS层数据导入脚本	64

#### 5.4 DWD层	65
 * 5.4.1 创建订单表	65
 * 5.4.2 创建订单详情表	65
 * 5.4.3 创建用户表	66
 * 5.4.4 创建支付流水表	66
 * 5.4.5 创建商品表（增加分类）	67
 * 5.4.6 DWD层数据导入脚本	67

#### 5.5 DWS层之用户行为宽表	69
 * 5.5.1 创建用户行为宽表	69
 * 5.5.2 用户行为数据宽表导入脚本	69

#### 5.6 ADS层（需求：GMV成交总额）	71
 * 5.6.1 建表语句	71
 * 5.6.2 数据导入脚本	71
 * 5.6.3 数据导出脚本	72

#### 5.7 Oozie基于Hue实现GMV指标全流程调度	73
 * 5.7.1 执行前的准备	73
 * 5.7.2 在Hue中创建Oozie任务GMV	74
 * 5.7.3 编写任务脚本并上传到HDFS	75
 * 5.7.4 编写任务调度	76
 * 5.7.5 执行任务调度	79

### 第6章 即席查询数仓搭建	79
#### 6.1 Impala安装	79
 * 6.1.1 添加服务	79
 * 6.1.2 选择Impala服务	80
 * 6.1.3 角色分配	80
 * 6.1.4 配置Impala	80
 * 6.1.5 启动Impala	81
 * 6.1.6 安装成功	81
 * 6.1.7 配置Hue支持Impala	82

#### 6.2 Impala基于Hue查询	82
### 第7章 Spark2.1安装	82
#### 7.1 升级过程	82
 * 7.1.1 离线包下载	82
 * 7.1.2 离线包上传	83

#### 7.2 页面操作	84
#### 7.1 更新Parcel	84
#### 7.2 点击分配	84
#### 7.3 点击激活	85
#### 7.4 回到首页点击添加服务	85
#### 7.5 点击Spark2继续	86
#### 7.6 选择一组依赖关系	86
#### 7.7 角色分配	86
#### 7.8 部署并启动	87
#### 7.9 命令行查看命令	88